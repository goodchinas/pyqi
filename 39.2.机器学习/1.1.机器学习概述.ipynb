{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>机器学习概述</font>\n",
    "# 定义\n",
    "\n",
    "`机器学习(Machine Learning,ML)` 有下面几种定义：\n",
    "\n",
    "* 机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能。\n",
    "* 机器学习是对能通过经验自动改进的计算机算法的研究。\n",
    "* 机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。\n",
    "\n",
    "另外：\n",
    "* 机器学习是通过编程让计算机从数据中进行学习的科学（和艺术）。\n",
    "* 机器学习是让计算机具有学习的能力，无需进行明确编程。 —— 亚瑟·萨缪尔，1959\n",
    "* 计算机程序利用经验 E 学习任务 T，性能是 P，如果针对任务 T 的性能 P 随着经验 E 不断增长，则称为机器学习。 —— 汤姆·米切尔，1997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特点\n",
    "## 传统方法\n",
    "1. 分析数据；\n",
    "2. 实现规则；\n",
    "3. 分析效果，重复1,2，直至效果满意；\n",
    "<img src='images/286f80869737859c1d2d0440461b8b1c.png'>\n",
    "\n",
    "## 机器学习\n",
    "### 自动学习\n",
    "<img src='images/a47564330dc27ae908ff1adb256c669f.png'>\n",
    "\n",
    "### 适应改变\n",
    "<img src='images/a5476395facbd7e47efb8edd05f5cfd1.png'>\n",
    "\n",
    "### 反馈人类\n",
    "<img src='images/bcf58699a53e5bf438a585823e759191.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类\n",
    "机器学习有多种类型，可以根据如下规则进行分类：\n",
    "\n",
    "* 根据预测目标是离散型还是连续型（分类、回归）  \n",
    "* 是否在人类监督下进行训练（监督，非监督，半监督和强化学习）\n",
    "* 是否可以动态渐进学习（在线学习 vs 批量学习）\n",
    "\n",
    "## 分类/回归\n",
    "* 分类（classification）：将实例数据划分到合适的类别中。\n",
    "   * 应用实例：判断网站是否被黑客入侵（二分类 ），手写数字的自动识别（多分类）\n",
    "* 回归（regression）：主要用于预测数值型数据。\n",
    "   * 应用实例：股票价格波动的预测，房屋价格的预测等。\n",
    "   \n",
    "## 监督/非监督学习\n",
    "机器学习可以根据训练时监督的量和类型进行分类。主要有四类：监督学习、非监督学习、半监督学习和强化学习。\n",
    "### 监督学习（supervised learning）\n",
    "* 必须确定目标变量的值，以便机器学习算法可以发现特征和目标变量之间的关系。在监督学习中，给定一组数据，我们知道正确的输出结果应该是什么样子，并且知道在输入和输出之间有着一个特定的关系。 (包括：分类和回归)\n",
    "<table><tr>\n",
    "    <td><img src='images/06ab618424c80142a5832c5c1f788281.png'></td>\n",
    "    <td><img src='images/2963f105f532a50f073764a5e6e20290.png'></td>\n",
    "    </tr></table>\n",
    "* 样本集：训练数据 + 测试数据\n",
    "    * 训练样本 = 特征(feature) + 目标变量(label: 分类-离散值/回归-连续值)\n",
    "    * 特征通常是训练样本集的列，它们是独立测量得到的。\n",
    "    * 目标变量: 目标变量是机器学习预测算法的测试结果。\n",
    "        * 在分类算法中目标变量的类型通常是标称型(如：真与假)，而在回归算法中通常是连续型(如：1~100)。\n",
    "* 监督学习需要注意的问题：\n",
    "    * 偏差和方差权衡\n",
    "    * 功能的复杂性和数量的训练数据\n",
    "    * 输入空间的维数特征(DNN,CNN,RNN)\n",
    "* 一些回归算法也可以用来进行分类,例如，逻辑回归通常用来进行分类，它可以生成一个归属某一类的可能性的值.\n",
    "* 一些重要的监督学习算法：\n",
    "    * K近邻算法\n",
    "    * 线性回归\n",
    "    * 逻辑回归\n",
    "    * 支持向量机（SVM）\n",
    "    * 决策树和随机森林  \n",
    "    * 神经网络\n",
    "\n",
    "### 非监督学习（unsupervised learing）\n",
    "* 在机器学习，无监督学习的问题是，在未加标签的数据中，试图找到隐藏的结构。因为提供给学习者的实例是未标记的，因此没有错误或报酬信号来评估潜在的解决方案。\n",
    "<img src='images/f72a1bb88f7e5b57afa03d839c27f786.png'>\n",
    "\n",
    "* 无监督学习是密切相关的统计数据密度估计的问题。然而无监督学习还包括寻求，总结和解释数据的主要特点等诸多技术。无监督学习使用的许多方法是，基于用于处理数据的数据挖掘方法。\n",
    "* 数据没有类别信息，也不会给定目标值。\n",
    "* 非监督学习包括的类型：\n",
    "  * 聚类：在无监督学习中，将数据集分成由类似的对象组成多个类的过程称为聚类。\n",
    "  * 密度估计：通过样本分布的紧密程度，来估计与分组的相似性。\n",
    "  * 此外，无监督学习还可以减少数据特征的维度，以便我们可以使用二维或三维图形更加直观地展示数据信息。\n",
    "  * 异常检测（anomaly detection）\n",
    "<img src='images/460a99aa622874f69517566b4400b97d.png'>\n",
    "* 一些最重要的非监督学习算法：\n",
    "    *   **聚类**  \n",
    "        * K 均值  \n",
    "        * 层次聚类分析（Hierarchical Cluster Analysis，HCA）  \n",
    "        * 期望最大值\n",
    "    *   **可视化和降维**  \n",
    "        * 主成分分析（Principal Component Analysis，PCA）  \n",
    "        * 核主成分分析  \n",
    "        * 局部线性嵌入（Locally-Linear Embedding，LLE）  \n",
    "        * t-分布邻域嵌入算法（t-distributed Stochastic Neighbor Embedding，t-SNE）\n",
    "    *   **关联性规则学习**  \n",
    "        * Apriori 算法  \n",
    "        * Eclat 算法\n",
    "        \n",
    "### 半监督学习\n",
    "一些算法可以处理部分带标签的训练数据，通常是大量不带标签数据加上小部分带标签数据。这称作半监督学习，多数半监督学习算法是非监督和监督算法的结合。例如，深度信念网络（deep belief networks）是基于被称为互相叠加的受限玻尔兹曼机（restricted Boltzmann machines，RBM）的非监督组件。RBM 是先用非监督方法进行训练，再用监督学习方法对整个系统进行微调。\n",
    "<img src='images/36b0385880667b8755ada314c430c239.png'>\n",
    "\n",
    "### 强化学习\n",
    "强化学习非常不同。学习系统在这里被称为智能体（agent），可以对环境进行观察、选择和执行动作，并获得奖励作为回报（负奖励是惩罚）。然后它必须自己学习哪个是最佳方法（称为策略，policy），以得到长久的最大奖励。策略决定了智能体在给定情况下应该采取的行动。也就是说，强化学习算法可以训练程序做出某一决定。程序在某一情况下尝试所有的可能行动，记录不同行动的结果并试着找出最好的一次尝试来做决定。\n",
    "<img src='images/ceab81ad58acd2853a3af59efd78a347.png'>\n",
    "\n",
    "## 批量和在线学习\n",
    "另一个用来分类机器学习的准则是，它是否能从导入的数据流进行持续学习。\n",
    "### 批量学习\n",
    "在批量学习中，系统不能进行持续学习：必须用所有可用数据进行训练。这通常会占用大量时间和计算资源，所以一般是线下做的。首先是进行训练，然后部署在生产环境且停止学习，它只是使用已经学到的策略。这称为离线学习。\n",
    "\n",
    "如果你想让一个批量学习系统了解新数据，就需要从头训练一个系统的新版本，使用全部数据集（包括新数据也有老数据），然后停掉老系统，换上新系统。\n",
    "\n",
    "当然，训练、评估、部署一套机器学习的系统的整个过程可以自动进行（见下图），所以即便是批量学习也可以适应改变。只要有需要，就可以方便地更新数据、训练一个新版本。\n",
    "\n",
    "<img src='images/a5476395facbd7e47efb8edd05f5cfd1.png'>\n",
    "\n",
    "\n",
    "这个方法很简单，通常可以满足需求，但是用全部数据集进行训练会花费大量时间，所以一般是每 24 小时或每周训练一个新系统。如果系统需要快速适应变化的数据（比如，预测股价变化），就需要一个响应更及时的方案。\n",
    "\n",
    "另外，用全部数据训练需要大量计算资源（CPU、内存空间、磁盘空间、磁盘 I/O、网络 I/O 等等）。如果你有大量数据，并让系统每天自动从头开始训练，就会开销很大。如果数据量巨大，甚至无法使用批量学习算法。\n",
    "\n",
    "最后，如果你的系统需要自动学习，但是资源有限，处理大量训练数据、每天花费数小时的大量资源进行训练是不实际的。对于这些情况，需要使用持续学习方案。\n",
    "### 在线学习\n",
    "在线学习中，是用数据实例持续地进行训练，可以一次一个或一次几个实例（称为小批量）。每个学习步骤都很快且廉价，所以系统可以动态地学习收到的最新数据（见下图）。\n",
    "<img src='images/835b6939f1d9bdd7b42e44b993e53f4d.png'>\n",
    "在线学习很适合系统接收连续流的数据（比如，股票价格），且需要自动对改变作出调整。如果计算资源有限，在线学习是一个不错的方案：一旦在线学习系统学习了新的数据实例，它就不再需要这些数据了，所以可以扔掉这些数据。这样可以节省大量的空间。\n",
    "\n",
    "在线学习算法也适用于在超大数据集（一台计算机不足以用于存储它）上训练系统（这称作核外学习，*out-of-core* learning）。算法每次只加载部分数据，用这些数据进行训练，然后重复这个过程，直到使用完所有数据。\n",
    "\n",
    "在线学习系统的一个重要参数是，它们可以多快地适应数据的改变：这被称为学习速率。如果你设定一个高学习速率，系统就可以快速适应新数据，但是也会快速忘记老数据。相反的，如果你设定的学习速率低，系统的惰性就会强：即，它学的更慢，但对新数据中的噪声或没有代表性的数据点结果不那么敏感。\n",
    "\n",
    "在线学习的挑战之一是，如果坏数据被用来进行训练，系统的性能就会逐渐下滑。要减小这种风险，你需要密集监测，如果检测到性能下降，要快速关闭（或是滚回到一个之前的状态）。你可能还要监测输入数据，对反常数据做出反应（比如，使用异常检测算法）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 专业术语\n",
    "* 模型（model）：计算机层面的认知\n",
    "* 学习算法（learning algorithm），从数据中产生模型的方法\n",
    "* 数据集（data set）：一组记录的合集\n",
    "* 示例（instance）：对于某个对象的描述\n",
    "* 样本（sample）：也叫示例\n",
    "* 属性（attribute）：对象的某方面表现或特征\n",
    "* 特征（feature）：同属性\n",
    "* 属性值（attribute value）：属性上的取值\n",
    "* 属性空间（attribute space）：属性张成的空间\n",
    "* 样本空间/输入空间（samplespace）：同属性空间\n",
    "* 特征向量（feature vector）：在属性空间里每个点对应一个坐标向量，把一个示例称作特征向量\n",
    "* 维数（dimensionality）：描述样本参数的个数（也就是空间是几维的）\n",
    "* 学习（learning）/训练（training）：从数据中学得模型\n",
    "* 训练数据（training data）：训练过程中用到的数据\n",
    "* 训练样本（training sample）:训练用到的每个样本\n",
    "* 训练集（training set）：训练样本组成的集合\n",
    "* 假设（hypothesis）：学习模型对应了关于数据的某种潜在规则\n",
    "* 真相（ground-truth）:真正存在的潜在规律\n",
    "* 学习器（learner）：模型的另一种叫法，把学习算法在给定数据和参数空间的实例化\n",
    "* 预测（prediction）：判断一个东西的属性\n",
    "* 标记（label）：关于示例的结果信息，比如我是一个“好人”。\n",
    "* 样例（example）：拥有标记的示例\n",
    "* 标记空间/输出空间（label space）：所有标记的集合\n",
    "* 分类（classification）：预测是离散值，比如把人分为好人和坏人之类的学习任务\n",
    "* 回归（regression）：预测值是连续值，比如你的好人程度达到了0.9，0.6之类的\n",
    "* 二分类（binary classification）：只涉及两个类别的分类任务\n",
    "* 正类（positive class）：二分类里的一个\n",
    "* 反类（negative class）：二分类里的另外一个\n",
    "* 多分类（multi-class classification）：涉及多个类别的分类\n",
    "* 测试（testing）：学习到模型之后对样本进行预测的过程\n",
    "* 测试样本（testing sample）：被预测的样本\n",
    "* 聚类（clustering）：把训练集中的对象分为若干组\n",
    "* 簇（cluster）：每一个组叫簇\n",
    "* 监督学习（supervised learning）：典范--分类和回归\n",
    "* 无监督学习（unsupervised learning）：典范--聚类\n",
    "* 未见示例（unseen instance）：“新样本“，没训练过的样本\n",
    "* 泛化（generalization）能力：学得的模型适用于新样本的能力\n",
    "* 分布（distribution）：样本空间的全体样本服从的一种规律\n",
    "* 独立同分布（independent and identically distributed，简称i,i,d.）:获得的每个样本都是独立地从这个分布上采样获得的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开发流程\n",
    "1. 收集数据: 收集样本数据\n",
    "2. 准备数据: 清洗格式数据\n",
    "3. 分析数据: 分析了解数据；\n",
    "4. 训练算法: [机器学习算法核心]如果使用无监督学习算法，由于不存在目标变量值，则可以跳过该步骤\n",
    "5. 测试算法: [机器学习算法核心]评估算法效果\n",
    "6. 使用算法: 将机器学习算法转为应用程序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集的划分\n",
    " * 训练集（Training set） —— 学习样本数据集，通过匹配一些参数来建立一个模型，主要用来训练模型。类比考研前做的解题大全。\n",
    " * 验证集（validation set） —— 对学习出来的模型，调整模型的参数，如在神经网络中选择隐藏单元数。验证集还用来确定网络结构或者控制模型复杂程度的参数。类比 考研之前做的模拟考试。\n",
    " * 测试集（Test set） —— 测试训练好的模型的分辨能力。类比 考研。这次真的是一考定终身。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主要挑战\n",
    "简而言之，开展机器学习任务，就是是选择一个学习算法并用一些数据进行训练，然后在测试数据上验证，如此循环，直至性能达标。那么其中会导致错误的两件事就是“错误的算法”和“错误的数据”。我们从错误的数据开始。\n",
    "## 错误的数据\n",
    "### 训练数据量不足\n",
    "在一篇 2001 年发表的[著名论文](http://ucrel.lancs.ac.uk/acl/P/P01/P01-1005.pdf)中，微软研究员 Michele Banko 和 Eric Brill 展示了不同的机器学习算法，包括非常简单的算法，一旦有了大量数据进行训练，在进行去除语言歧义的测试中几乎有相同的性能（见下图）。\n",
    "<img src='images/df0a0c8fd4ac783e110e474ea7e6aa51.png'>\n",
    "对于复杂问题，数据比算法更重要的主张在 2009 年由 Norvig 发表的论文[《The Unreasonable Effectiveness of Data》](https://link.jianshu.com?t=http%3A%2F%2Fstatic.googleusercontent.com%2Fmedia%2Fresearch.google.com%2Ffr%2F%2Fpubs%2Farchive%2F35179.pdf)得到了进一步的推广。但是，应该注意到，对于很多任务，小型和中型的数据集仍然是非常常见的，获得额外的训练数据并不总是轻易和廉价的，所以不要忽视算法的差异。\n",
    "### 没有代表性的训练数据\n",
    "为了更好地进行归纳推广，让训练数据对新数据具有代表性是非常重要的，这决定了模型的泛化能力，即在验证集、测试集以及在生产上的表现。\n",
    "<img src='images/baf1ea813fab791c5f3e80e016e69eec.png'>\n",
    "### 低质量数据\n",
    "很明显，如果训练集中的错误、异常值和噪声（错误测量引入的）太多，系统检测出潜在规律的难度就会变大，性能就会降低。花费时间对训练数据进行清理是十分重要的。事实上，大多数据科学家的一大部分时间是做清洗工作的。例如：\n",
    "*   如果一些实例是明显的异常值，最好删掉它们或尝试手工修改错误；\n",
    "*   如果一些实例缺少特征，你必须决定是否忽略这个属性、忽略这些实例、填入缺失值，或者训练一个含有这个特征的模型和一个不含有这个特征的模型，等等。\n",
    "\n",
    "### 不相关的特征\n",
    "\n",
    "俗语说：如果进来的是垃圾，那么出去的也是垃圾。你的系统只有在训练数据包含足够相关特征、非相关特征不多的情况下，才能进行学习。机器学习项目成功的关键之一是用好的特征进行训练。这个过程称作特征工程，包括：\n",
    "*   特征选择：在所有存在的特征中选取最有用的特征进行训练。\n",
    "*   特征提取：组合存在的特征，生成一个更有用的特征（如前面看到的，可以使用降维算法）。\n",
    "*   收集新数据创建新特征。\n",
    "\n",
    "现在，我们已经看过了许多坏数据的例子，接下来看几个坏算法的例子。\n",
    "## 错误的算法\n",
    "### 过拟合训练数据\n",
    "模型把训练样本学习“太好了”，可能把一些训练样本自身的特性当做了所有潜在样本都有的一般性质，导致泛化能力下降。\n",
    "\n",
    "过拟合发生在相对于训练数据的量和噪声，模型过于复杂的情况。可能的解决方案有：\n",
    "* 简化模型，可以通过选择一个参数更少的模型（比如使用线性模型，而不是高阶多项式模型）、减少训练数据的属性数、或限制一下模型（正则化）\n",
    "* 收集更多的训练数据\n",
    "* 减小训练数据的噪声（比如，修改数据错误和去除异常值）\n",
    "\n",
    "### 欠拟合训练数据\n",
    "欠拟合是和过拟合相对的，模型没有很好地捕捉到数据特征，不能够很好地拟合数据，对训练样本的一般性质尚未学好。\n",
    "解决这个问题的选项包括：\n",
    "*   选择一个更强大的模型，带有更多参数\n",
    "*   用更好的特征训练学习算法（特征工程）\n",
    "*   减小对模型的限制（比如，减小正则化超参数）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结\n",
    "* 机器学习是让机器通过学习数据对某些任务做得更好，而不使用确定的代码规则。\n",
    "* 有许多不同类型的机器学习系统：监督或非监督，批量或在线等等。\n",
    "* 在机器学习项目中，我们从训练集中收集数据，然后对学习算法进行训练。\n",
    "* 如果训练集太小、数据没有代表性、含有噪声、或掺有不相关的特征（垃圾进，垃圾出），系统的性能不会好。\n",
    "* 模型不能太简单（会发生欠拟合），也不能太复杂（会发生过拟合）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
